{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9a93b446-53cb-4c79-b0dc-6c92c0e0c7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f897940c-c4f5-4231-af7c-3521bac6dd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "league_id = \"1125189236732284928\"\n",
    "url = f\"https://api.sleeper.app/v1/league/{league_id}/drafts\"\n",
    "response = requests.get(url)\n",
    "data = response.json()\n",
    "\n",
    "draft_id = data[0]['draft_id'] #the startup draft\n",
    "picks_url = f\"https://api.sleeper.app/v1/draft/{draft_id}/picks\"\n",
    "picks = requests.get(picks_url).json()\n",
    "\n",
    "entry_draft = pd.DataFrame(picks)\n",
    "metadata_entry_draft = entry_draft['metadata'].apply(pd.Series)\n",
    "entry_draft = pd.concat([entry_draft.drop(columns=['metadata']), metadata_entry_draft], axis=1)\n",
    "entry_draft = entry_draft[['round', 'pick_no', 'roster_id', 'first_name', 'last_name', 'position', 'team']]\n",
    "entry_draft = entry_draft.sort_values(by='pick_no')\n",
    "\n",
    "rosters = requests.get(f\"https://api.sleeper.app/v1/league/{league_id}/rosters\").json()\n",
    "users = requests.get(f\"https://api.sleeper.app/v1/league/{league_id}/users\").json()\n",
    "\n",
    "roster_map = {r['roster_id']: r['owner_id'] for r in rosters}\n",
    "user_map = {u['user_id']: u['display_name'] for u in users}\n",
    "\n",
    "entry_draft['owner_id'] = entry_draft['roster_id'].map(roster_map)\n",
    "entry_draft['owner_name'] = entry_draft['owner_id'].map(user_map)\n",
    "del entry_draft['owner_id']\n",
    "del entry_draft['roster_id']\n",
    "\n",
    "entry_draft.to_csv('entry_draft.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dc008d72-53ef-4407-99cf-1ad17dea7d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "league_id = \"1184039966157762560\"\n",
    "url = f\"https://api.sleeper.app/v1/league/{league_id}/drafts\"\n",
    "response = requests.get(url)\n",
    "data = response.json()\n",
    "draft_id = data[0]['draft_id'] #the 2025 rookie draft\n",
    "picks_url = f\"https://api.sleeper.app/v1/draft/{draft_id}/picks\"\n",
    "picks = requests.get(picks_url).json()\n",
    "rookie_draft = pd.DataFrame(picks)\n",
    "metadata_rookie_draft = rookie_draft['metadata'].apply(pd.Series)\n",
    "rookie_draft = pd.concat([rookie_draft.drop(columns=['metadata']), metadata_rookie_draft], axis=1)\n",
    "rookie_draft = rookie_draft[['round', 'pick_no', 'roster_id', 'first_name', 'last_name', 'position', 'team']]\n",
    "rookie_draft = rookie_draft.sort_values(by='pick_no')\n",
    "rosters = requests.get(f\"https://api.sleeper.app/v1/league/{league_id}/rosters\").json()\n",
    "users = requests.get(f\"https://api.sleeper.app/v1/league/{league_id}/users\").json()\n",
    "\n",
    "roster_map = {r['roster_id']: r['owner_id'] for r in rosters}\n",
    "user_map = {u['user_id']: u['display_name'] for u in users}\n",
    "\n",
    "rookie_draft['owner_id'] = rookie_draft['roster_id'].map(roster_map)\n",
    "rookie_draft['owner_name'] = rookie_draft['owner_id'].map(user_map)\n",
    "del rookie_draft['owner_id']\n",
    "del rookie_draft['roster_id']\n",
    "\n",
    "rookie_draft.to_csv('rookie_draft.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6f6035bb-a355-4f06-ba83-007ba0789710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Draft started at: 2024-08-11 18:01:07.164000\n"
     ]
    }
   ],
   "source": [
    "#finding the start date/time of the entry draft\n",
    "\n",
    "league_id = \"1125189236732284928\"\n",
    "drafts = requests.get(f\"https://api.sleeper.app/v1/league/{league_id}/drafts\").json()\n",
    "\n",
    "startup_draft = drafts[0]  # assuming this is the entry draft\n",
    "start_time_epoch = startup_draft['start_time']  # in UNIX epoch (milliseconds)\n",
    "\n",
    "start_time = datetime.fromtimestamp(start_time_epoch / 1000)  # if in ms\n",
    "print(\"Draft started at:\", start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "41dbac52-23f0-43a4-8bb6-0ead2db3e098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file has been created successfully.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Fetch the webpage content\n",
    "url = \"https://www.fantasypros.com/2024/08/superflex-dynasty-fantasy-football-draft-rankings-expert-picks-tiers/\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# Extract the table rows containing player data\n",
    "rows = soup.find_all(\"tr\")\n",
    "\n",
    "# Initialize a list to hold the player data\n",
    "data = []\n",
    "\n",
    "# Iterate over each row and extract the relevant columns\n",
    "for row in rows:\n",
    "    cols = row.find_all(\"td\")\n",
    "    if len(cols) >= 5:  # Ensure the row has enough columns\n",
    "        rank = cols[0].get_text(strip=True)\n",
    "        tier = cols[1].get_text(strip=True)\n",
    "        player_name = cols[2].get_text(strip=True)\n",
    "        team = cols[3].get_text(strip=True)\n",
    "        pos = cols[4].get_text(strip=True)\n",
    "        bye_week = cols[5].get_text(strip=True)\n",
    "        age = cols[6].get_text(strip=True)\n",
    "        data.append([rank, tier, player_name, team, pos, bye_week, age])\n",
    "\n",
    "# Create a DataFrame from the extracted data\n",
    "df = pd.DataFrame(data, columns=[\"Rank\", \"Tier\", \"Player Name\", \"Team\", \"Position\", \"Bye Week\", \"Age\"])\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(\"superflex_dynasty_rankings_2024.csv\", index=False)\n",
    "\n",
    "print(\"CSV file has been created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e2344f7e-a101-474c-a492-d6fd10b9b8e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file has been created successfully.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Fetch the webpage content\n",
    "url = \"https://www.fantasypros.com/nfl/rankings/dynasty-superflex.php\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# Extract the table rows containing player data\n",
    "rows = soup.find_all(\"tr\")\n",
    "\n",
    "# Initialize a list to hold the player data\n",
    "data = []\n",
    "\n",
    "# Iterate over each row and extract the relevant columns\n",
    "for row in rows:\n",
    "    cols = row.find_all(\"td\")\n",
    "    if len(cols) >= 5:  # Ensure the row has enough columns\n",
    "        rank = cols[0].get_text(strip=True)\n",
    "        tier = cols[1].get_text(strip=True)\n",
    "        player_name = cols[2].get_text(strip=True)\n",
    "        team = cols[3].get_text(strip=True)\n",
    "        pos = cols[4].get_text(strip=True)\n",
    "        bye_week = cols[5].get_text(strip=True)\n",
    "        age = cols[6].get_text(strip=True)\n",
    "        data.append([rank, tier, player_name, team, pos, bye_week, age])\n",
    "\n",
    "# Create a DataFrame from the extracted data\n",
    "df = pd.DataFrame(data, columns=[\"Rank\", \"Tier\", \"Player Name\", \"Team\", \"Position\", \"Bye Week\", \"Age\"])\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(\"superflex_dynasty_rankings.csv\", index=False)\n",
    "\n",
    "print(\"CSV file has been created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fff915bc-b1bc-4456-83b0-7d6d0dac7105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV saved successfully!\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Setup headless Chrome browser\n",
    "options = Options()\n",
    "options.headless = True\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "url = \"https://www.fantasypros.com/nfl/rankings/dynasty-superflex.php\"\n",
    "driver.get(url)\n",
    "\n",
    "# Wait for page to fully load JS content (adjust if necessary)\n",
    "time.sleep(25)\n",
    "\n",
    "# Get the fully rendered HTML\n",
    "html = driver.page_source\n",
    "driver.quit()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# Now find the table with rankings\n",
    "table = soup.find(\"table\")  # FantasyPros tables usually have id=\"data\"\n",
    "\n",
    "data = []\n",
    "headers = [th.text.strip() for th in table.find(\"thead\").find_all(\"th\")]\n",
    "\n",
    "for row in table.find(\"tbody\").find_all(\"tr\"):\n",
    "    cols = [td.text.strip() for td in row.find_all(\"td\")]\n",
    "    data.append(cols)\n",
    "\n",
    "df = pd.DataFrame(data, columns=headers)\n",
    "df.to_csv(\"superflex_dynasty_rankings_selenium.csv\", index=False)\n",
    "print(\"CSV saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c5b1d7-a8cc-4806-94a7-d931dbe53436",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
